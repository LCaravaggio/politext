{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/politext/blob/snowball/GS_v0_2_con_vocab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "with open(\"/content/drive/My Drive/kaggle.json\", 'r') as f:\n",
        "    api_token= json.load(f)\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d leonardocaravaggio/base-diputados -f base_formateada_snowball.csv\n",
        "!kaggle datasets download -d leonardocaravaggio/base-diputados -f vocabulary_snowball.voc"
      ],
      "metadata": {
        "id": "awzWHLIq04IV",
        "outputId": "050dc5bf-b390-438b-c35e-5f9dc116e864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Mounted at /content/drive\n",
            "base_formateada_snowball.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "vocabulary_snowball.voc.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()"
      ],
      "metadata": {
        "id": "F0LeC-DG2hrj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "base=pd.read_csv('base_formateada_snowball.csv')"
      ],
      "metadata": {
        "id": "vYV6fAC_1kpA",
        "outputId": "d9f81657-c67b-4309-d08b-68f7a9e2953d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9ac41a69d66e>:2: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  base=pd.read_csv('base_formateada_snowball.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('vocabulary_snowball.voc', 'rb') as f:\n",
        "    inter = pickle.load(f)"
      ],
      "metadata": {
        "id": "zH0ijy3r1wFv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer(ngram_range=(2,2) ,vocabulary=inter)\n",
        "matrix = vect.fit_transform(base['tokens'])"
      ],
      "metadata": {
        "id": "j4kIpxNJk555"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1yWjac_lrJv",
        "outputId": "46ba9d62-f486-4584-f0fd-0ea570721b38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "357780"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta celda tarda unos 120 minutos en correr\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=30, max_iter=50, learning_method='batch', learning_offset=50.,random_state=0)\n",
        "lda.fit(matrix)"
      ],
      "metadata": {
        "id": "_WewtbEPkyOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import argsort\n",
        "import statistics\n",
        "from statistics import mode\n",
        "from scipy.special import logsumexp\n",
        "import scipy as sp"
      ],
      "metadata": {
        "id": "Ka3t_6Rt4ns3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topics por weights"
      ],
      "metadata": {
        "id": "pPi0u9Vs2__N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disc_weights=matrix*lda.components_.transpose()"
      ],
      "metadata": {
        "id": "wuZwn2t22_S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base['Topic_weight']=disc_weights.argmax(axis=1)+1"
      ],
      "metadata": {
        "id": "v5olK9E54dWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base.fecha=pd.to_datetime(base.fecha, infer_datetime_format=True)"
      ],
      "metadata": {
        "id": "xFWRKyXb-9PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por LEGISLATURA por WEIGHTS\n",
        "legislaturas=['I', 'II', 'III', 'IV', 'V', 'VI', 'VII','VIII', 'IX', 'X', 'XI', 'XII','XIII']\n",
        "topics_por_legislatura=pd.DataFrame()\n",
        "for x in legislaturas:\n",
        "  base_legislatura=base[base.legislatura==x]\n",
        "  topics_por_legislatura[x]=base_legislatura['Topic_weight'].value_counts().sort_index()/base_legislatura['Topic_weight'].value_counts().sort_index().sum()\n",
        "topics_por_legislatura.to_csv('topics_por_legislatura_por_weights.csv')"
      ],
      "metadata": {
        "id": "ibnmT6C08Aio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por AÑO por weights\n",
        "topics_por_año=pd.DataFrame()\n",
        "for x in range (1979, 2020):\n",
        "  base_year=base[pd.DatetimeIndex(base.fecha).year==x]\n",
        "  topics_por_año[x]=base_year['Topic_weight'].value_counts().sort_index()/base_year['Topic_weight'].value_counts().sort_index().sum()\n",
        "topics_por_año.to_csv('topics_por_año_por_weights.csv')"
      ],
      "metadata": {
        "id": "FP85kg4w8TD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FREX"
      ],
      "metadata": {
        "id": "nqYeg_ip6kKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frex(mod, w=0.7):\n",
        "    log_beta = np.log(mod.components_)\n",
        "    log_exclusivity = log_beta - logsumexp(log_beta, axis=0)\n",
        "    exclusivity_ecdf = np.apply_along_axis(ecdf, 1, log_exclusivity)\n",
        "    freq_ecdf = np.apply_along_axis(ecdf, 1, log_beta)\n",
        "    out = 1. / (w / exclusivity_ecdf + (1 - w) / freq_ecdf)\n",
        "    return out\n",
        "\n",
        "def ecdf(arr):\n",
        "    return sp.stats.rankdata(arr, method='max') / arr.size\n",
        "\n",
        "def t_FREX(row):\n",
        "  return frex_df[matrix[row['id']].argmax()].argsort()[9]"
      ],
      "metadata": {
        "id": "opW4qtxs4jwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frex_df=pd.DataFrame(frex(lda))"
      ],
      "metadata": {
        "id": "nCdMHn7m7TR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una columna con el topic que se asigna por frex a cada discurso de la base\n",
        "base['id']=range(0,334421)\n",
        "base['Topic_FREX']=base.apply (lambda row: t_FREX(row), axis=1)+1"
      ],
      "metadata": {
        "id": "39ai_N8J7YHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por LEGISLATURA por FREX\n",
        "legislaturas=['I', 'II', 'III', 'IV', 'V', 'VI', 'VII','VIII', 'IX', 'X', 'XI', 'XII','XIII']\n",
        "topics_por_legislatura=pd.DataFrame()\n",
        "for x in legislaturas:\n",
        "  base_legislatura=base[base.legislatura==x]\n",
        "  topics_por_legislatura[x]=base_legislatura['Topic_FREX'].value_counts().sort_index()/base_legislatura['Topic_FREX'].value_counts().sort_index().sum()\n",
        "topics_por_legislatura.to_csv('topics_por_legislatura_por_frex.csv')"
      ],
      "metadata": {
        "id": "LxIdy9yS_hmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por AÑO por FREX\n",
        "topics_por_año=pd.DataFrame()\n",
        "for x in range (1979, 2020):\n",
        "  base_year=base[pd.DatetimeIndex(base.fecha).year==x]\n",
        "  topics_por_año[x]=base_year['Topic_FREX'].value_counts().sort_index()/base_year['Topic_FREX'].value_counts().sort_index().sum()\n",
        "topics_por_año.to_csv('topics_por_año_por_frex.csv')"
      ],
      "metadata": {
        "id": "2Y7uEKEL_qCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigramas por weights"
      ],
      "metadata": {
        "id": "P0GTL-2pWXmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas=pd.DataFrame()\n",
        "feature_names=vect.get_feature_names_out()\n",
        "no_top_words=20\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  bigramas[\"Topic %d:\" % (topic_idx + 1)]=[feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]"
      ],
      "metadata": {
        "id": "p0seVyONXtTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas.to_csv('bigramas_por_weights_30topics.csv')"
      ],
      "metadata": {
        "id": "_ZWDdtUaYf79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigramas por frex"
      ],
      "metadata": {
        "id": "GK1BTUXxm047"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"Topic %d:\" % (topic_idx + 1)\n",
        "for topic_idx, topic in enumerate(frex(lda)):\n",
        "  bigramas[\"Topic %d:\" % (topic_idx + 1)]=[feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]"
      ],
      "metadata": {
        "id": "ahCMverxaAay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas.to_csv('bigramas_por_frex_30topics.csv')"
      ],
      "metadata": {
        "id": "bHwC8aO2eO-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigramas para 10 Topics"
      ],
      "metadata": {
        "id": "jPBncuy4ecm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta celda tarda unos 25 minutos en correr\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=10, max_iter=50, learning_method='batch', learning_offset=50.,random_state=0)\n",
        "lda.fit(matrix)"
      ],
      "metadata": {
        "id": "vV7CmRnrecDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas=pd.DataFrame()\n",
        "feature_names=vect.get_feature_names_out()\n",
        "no_top_words=20\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  bigramas[\"Topic %d:\" % (topic_idx + 1)]=[feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]"
      ],
      "metadata": {
        "id": "J6uh66frehCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas.to_csv('bigramas_por_weights_10topics.csv')"
      ],
      "metadata": {
        "id": "4mPdtNjUehCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Topic %d:\" % (topic_idx + 1)\n",
        "for topic_idx, topic in enumerate(frex(lda)):\n",
        "  bigramas[\"Topic %d:\" % (topic_idx + 1)]=[feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]"
      ],
      "metadata": {
        "id": "v3rfzoYfehCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigramas.to_csv('bigramas_por_frex_10topics.csv')"
      ],
      "metadata": {
        "id": "bZOM9hVhehCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bajada"
      ],
      "metadata": {
        "id": "KMVCy9r36EmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('topics_por_legislatura_por_weights.csv')\n",
        "files.download('topics_por_año_por_weights.csv')\n",
        "files.download('topics_por_legislatura_por_frex.csv')\n",
        "files.download('topics_por_año_por_frex.csv')\n",
        "files.download('bigramas_por_weights_30topics.csv')\n",
        "files.download('bigramas_por_frex_30topics.csv')\n",
        "files.download('bigramas_por_weights_10topics.csv')\n",
        "files.download('bigramas_por_frex_10topics.csv')"
      ],
      "metadata": {
        "id": "LIz1QY-m6D-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}