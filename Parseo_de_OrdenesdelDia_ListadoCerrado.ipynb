{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP/8KYH5ipHYmHeWijTh9p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/politext/blob/snowball/Parseo_de_OrdenesdelDia_ListadoCerrado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S_UEBLg81wW",
        "outputId": "86f122fe-eeef-41a4-b968-0860671f35f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading Scraps%20PDFs.csv.zip to /content\n",
            " 97% 228M/234M [00:03<00:00, 107MB/s] \n",
            "100% 234M/234M [00:03<00:00, 67.0MB/s]\n",
            "Downloading base_formateada_senado_snowball.csv.zip to /content\n",
            " 92% 132M/143M [00:03<00:00, 45.8MB/s]\n",
            "100% 143M/143M [00:03<00:00, 37.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "with open(\"/content/drive/My Drive/kaggle.json\", 'r') as f:\n",
        "    api_token= json.load(f)\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d leonardocaravaggio/scraps-pdfs -f \"Scraps PDFs.csv\"\n",
        "!kaggle datasets download -d leonardocaravaggio/scraps-pdfs -f \"base_formateada_senado_snowball.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()"
      ],
      "metadata": {
        "id": "gwJL1yMZ9zbE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la base\n",
        "base = pd.read_csv('/content/Scraps PDFs.csv')\n",
        "base_parseada = pd.read_csv('/content/base_formateada_senado_snowball.csv')"
      ],
      "metadata": {
        "id": "IHPR981-91Ps",
        "outputId": "e1be9119-e9da-4ddd-ec3c-95e8cc7967e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e0eeee1141a8>:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  base_parseada = pd.read_csv('/content/base_formateada_senado_snowball.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_parseada.columns"
      ],
      "metadata": {
        "id": "fgmr3HKFmJeV",
        "outputId": "f43fe8a9-1659-40b1-fafe-69e26bd757f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Nombre/Cargo', 'Discurso', 'Cargo',\n",
              "       'Nombre', 'Link', 'Legislatura', 'tipo', 'fecha', 'fecha_formato',\n",
              "       'nombre', 'apellidos', 'procedLiteral', 'procedLugar', 'grupoNombre',\n",
              "       'tokens'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_parseada.Link[30]"
      ],
      "metadata": {
        "id": "228CnFJaNgyY",
        "outputId": "a4a8dfb7-71d8-4c14-ce47-28dc5da04dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.senado.es/legis10/publicaciones/pdf/senado/ds/DS_P_10_2.PDF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_despues_de_autor(cadena):\n",
        "    # Buscar la posición de la palabra \"Autor\" (sin importar mayúsculas o minúsculas)\n",
        "    posicion_autor = cadena.lower().find('autor')\n",
        "\n",
        "    # Si se encuentra la palabra \"Autor\"\n",
        "    if posicion_autor != -1:\n",
        "        # Eliminar todo lo que está después de la palabra \"Autor\"\n",
        "        cadena = cadena[:posicion_autor]\n",
        "    return cadena"
      ],
      "metadata": {
        "id": "Nnu9spPPtXMS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unir_strings_con_espacio(lista_strings):\n",
        "    nueva_lista = []\n",
        "    elemento_actual = \"\"\n",
        "\n",
        "    for elemento in lista_strings:\n",
        "        # Verificar si el elemento actual termina con un espacio\n",
        "        if elemento_actual.endswith(' '):\n",
        "            # Concatenar el elemento actual con el siguiente\n",
        "            elemento_actual = elemento_actual + elemento\n",
        "        else:\n",
        "            # Si no termina con espacio, agregar el elemento actual a la nueva lista\n",
        "            if elemento_actual:\n",
        "                nueva_lista.append(elemento_actual)\n",
        "            elemento_actual = elemento\n",
        "\n",
        "    # Agregar el último elemento a la nueva lista\n",
        "    if elemento_actual:\n",
        "        nueva_lista.append(elemento_actual)\n",
        "\n",
        "    return nueva_lista"
      ],
      "metadata": {
        "id": "R6WT2x9yyUV9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_occurrence(text, substring):\n",
        "    last_occurrence = -1\n",
        "    index = text.find(substring)\n",
        "\n",
        "    while index != -1:\n",
        "        last_occurrence = index\n",
        "        index = text.find(substring, index + 1)\n",
        "\n",
        "    return last_occurrence"
      ],
      "metadata": {
        "id": "fGlVrJdhXdoh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def generar(l):\n",
        "  df=pd.DataFrame(columns=['Nombre/Cargo', 'Discurso', 'Cargo',\n",
        "       'Nombre', 'Link', 'Legislatura', 'tipo', 'fecha', 'fecha_formato',\n",
        "       'nombre', 'apellidos', 'procedLiteral', 'procedLugar', 'grupoNombre',\n",
        "       'tokens', 'orden'])\n",
        "  fila=base['link'][base['link'] == l[6]].index[0]\n",
        "  texto=str(base.loc[fila].text)\n",
        "  discurso=str(l[3])\n",
        "\n",
        "  #ordenes = texto[texto.find('ORDEN DEL DÍA'):texto.find('SUMARIO')].split('\\n')\n",
        "  #ordenes=['JURAMENTO O PROMESA DE ACATAMIENTO A LA CONSTITUCIÓN.','1. ACTAS', '2. REGLAMENTO DEL SENADO', '3. INCOMPATIBILIDADES', '4. COMISIONES MIXTAS', '5. CONVENIOS Y ACUERDOS DE COOPERACIÓN ENTRE COMUNIDADES AUTÓNOMAS']\n",
        "  #patron = r'\\n\\n([\\s\\S]*?)\\n\\n'\n",
        "  #ordenes = re.findall(patron, texto[texto.find('ORDEN DEL DÍA'):texto.find('SUMARIO')])\n",
        "  #ordenes=texto[texto.find('ORDEN DEL DÍA'):texto.find('SUMARIO')].split('\\n')\n",
        "  orden_del_dia_pattern = re.compile(r'\\n(.*?)(?=\\n)', re.DOTALL)\n",
        "  matches = orden_del_dia_pattern.findall(texto[texto.find('ORDEN DEL DÍA'):texto.find('SUMARIO')])\n",
        "  adjusted_matches = []\n",
        "  for i, match in enumerate(matches):\n",
        "      # Eliminar espacio inicial si existe\n",
        "      match = match.lstrip()\n",
        "\n",
        "      # Si el match comienza con minúscula, hacer join con el match anterior\n",
        "      if match and match[0].islower() or match[:5]=='Autor' and i > 0:\n",
        "          try:\n",
        "            adjusted_matches[-1] += '' + match\n",
        "          except:\n",
        "            adjusted_matches = []\n",
        "\n",
        "      # Si el match comienza con '(', eliminar el match de la lista\n",
        "      elif match and match[0] == '(' or match=='Pleno' or match[:3]=='Núm':\n",
        "          continue\n",
        "      else:\n",
        "          adjusted_matches.append(match)\n",
        "\n",
        "  ordenes=adjusted_matches\n",
        "\n",
        "  o=0\n",
        "  ubic_anterior=0\n",
        "\n",
        "  ordenesnuevo=[]\n",
        "  for orden in ordenes:\n",
        "    if orden != 'JUNTA PREPARATORIA Y SESIÓN CONSTITUTIVA':\n",
        "      orden=str(eliminar_despues_de_autor(orden))\n",
        "      ordenesnuevo.append(orden.replace('— ','').replace('  ',' '))\n",
        "\n",
        "  ordenes=ordenesnuevo\n",
        "  ordenes=unir_strings_con_espacio(ordenes)\n",
        "  #print(ordenes)\n",
        "\n",
        "  for orden in ordenes:\n",
        "    #print(texto[texto.find('SUMARIO'):].replace('\\n','').replace('\\t', '').replace(' ','').find(l[2].replace('\\n','').replace('\\t', '').replace(' ','')+':'+ discurso.replace('\\t', '').replace('\\n','').replace(' ','')))\n",
        "    #print(texto[texto.find('SUMARIO'):].replace('\\n','').replace('\\t', '').replace(' ','').find(orden.upper().replace('\\n','').replace('\\t', '').replace(' ','')))\n",
        "    #print(texto[texto.find('SUMARIO'):].replace('\\n','').replace('\\t', '').replace(' ',''))\n",
        "    #print(l[2].replace('\\n','').replace('\\t', '').replace(' ','')+':'+discurso.replace('\\n','').replace('\\t', '').replace(' ',''))\n",
        "\n",
        "    texto_enelquebuscar=texto[texto.find('SUMARIO'):].replace('\\n','').replace('\\t','').replace(' ','')\n",
        "    discurso_con_nombre=str(str(l[2])+': '+str(l[3])).replace('\\n','').replace('\\t','').replace(' ','')\n",
        "    ubic_discurso=texto_enelquebuscar.find(discurso_con_nombre)\n",
        "    #ubic_titulo=texto_enelquebuscar.find(orden.upper().replace('\\n','').replace('\\t', '').replace(' ','')[3:])\n",
        "    ubic_titulo=find_last_occurrence(texto_enelquebuscar, str(orden).upper().replace('\\n','').replace('\\t', '').replace(' ','')[3:])\n",
        "    if ubic_titulo==-1: ubic_titulo=ubic_anterior+1\n",
        "    ubic_anterior=ubic_titulo\n",
        "    #print(ubic_titulo)\n",
        "    #print(ubic_discurso)\n",
        "    #print('----------')\n",
        "    if ubic_discurso>ubic_titulo: o+=1\n",
        "\n",
        "\n",
        "  #print(texto_enelquebuscar)\n",
        "  #print(discurso_con_nombre)\n",
        "  df['Nombre/Cargo']=[l[2]]\n",
        "  df['Discurso']=[l[3]]\n",
        "  df['Cargo']=[l[4]]\n",
        "  df['Nombre']=[l[5]]\n",
        "  df['Link']=[l[6]]\n",
        "  df['Legislatura']=[l[7]]\n",
        "  df['tipo']=[l[8]]\n",
        "  df['fecha']=[l[9]]\n",
        "  df['fecha_formato']=[l[10]]\n",
        "  df['nombre']=[l[11]]\n",
        "  df['apellidos']=[l[12]]\n",
        "  df['procedLiteral']=[l[13]]\n",
        "  df['procedLugar']=[l[14]]\n",
        "  df['grupoNombre']=[l[15]]\n",
        "  df['tokens']=[l[16]]\n",
        "  try:\n",
        "    df['orden']=[ordenes[o-1].upper()]\n",
        "  except:\n",
        "    df['orden']=[\"\"]\n",
        "\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "CzfD-9U7rQLj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base2=pd.DataFrame(columns=['Nombre/Cargo', 'Discurso', 'Cargo',\n",
        "       'Nombre', 'Link', 'Legislatura', 'tipo', 'fecha', 'fecha_formato',\n",
        "       'nombre', 'apellidos', 'procedLiteral', 'procedLugar', 'grupoNombre',\n",
        "       'tokens', 'orden'])"
      ],
      "metadata": {
        "id": "44C0UxVP4gjK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in base_parseada.values:\n",
        "  base2 = pd.concat([base2, generar(row)], axis=0)"
      ],
      "metadata": {
        "id": "ivCarVUHoA1b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base2"
      ],
      "metadata": {
        "id": "XBoIRK1zMV_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base2.Link[0]"
      ],
      "metadata": {
        "id": "2f0YJJ_LfFlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base2=base2.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "eqo1NUGkq_-Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base2['fecha_formato'] = pd.to_datetime(base2['fecha_formato'], errors='coerce')"
      ],
      "metadata": {
        "id": "5a7C0jzjjWdX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "base2.to_csv('base_formateada_senado_snowball_conorden.csv', escapechar='\\\\')\n",
        "files.download('base_formateada_senado_snowball_conorden.csv')"
      ],
      "metadata": {
        "id": "MddIYTC4BIJs",
        "outputId": "e9832714-0b15-4b28-f5cd-fb080facf331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1541aa96-f67a-4dfe-ab99-a2ec1eec7461\", \"base_formateada_senado_snowball_conorden.csv\", 585261043)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}